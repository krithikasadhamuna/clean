# AI SOC Platform - Server Configuration

server:
  host: "0.0.0.0"
  port: 80
  workers: 4
  log_level: "INFO"
  domain: "dev.codegrey.ai"
  
database:
  sqlite_path: "soc_database.db"
  elasticsearch:
    enabled: true
    host: "localhost"
    port: 9200
    index_prefix: "ai-soc"
  influxdb:
    enabled: true
    host: "localhost"
    port: 8086
    database: "ai_soc_metrics"
    
log_ingestion:
  batch_size: 1000
  flush_interval: 5
  max_buffer_size: 10000
  compression: true
  
detection:
  real_time_enabled: true
  ml_threshold: 0.7
  ai_analysis_enabled: true
  correlation_window: 3600
  
llm:
  provider: "openai"
  model: "gpt-3.5-turbo"
  temperature: 0.2
  max_tokens: 2048
  api_key: "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"
  analyze_all_logs: true
  ml_ai_comparison: true
  fallback_order: ["openai", "ollama"]
  
storage:
  retention_days: 90
  cold_storage_days: 30
  compression_enabled: true
  
monitoring:
  prometheus_enabled: true
  prometheus_port: 9090
  health_check_interval: 30
  
topology:
  continuous_monitoring: true
  update_interval: 30
  full_refresh_interval: 300
  change_notification: true
  attack_agent_integration: true

security:
  api_key_required: false
  development_mode: true
  rate_limiting: false
  max_requests_per_minute: 1000
  encryption_enabled: false

cors:
  allowed_origins:
    - "http://dev.codegrey.ai"
    - "https://dev.codegrey.ai"
    - "http://localhost:3000"
    - "http://localhost:3001"
    - "http://127.0.0.1:3000"
    - "*"
  allowed_methods:
    - "GET"
    - "POST" 
    - "PUT"
    - "DELETE"
    - "OPTIONS"
    - "PATCH"
  allowed_headers:
    - "Content-Type"
    - "Authorization"
    - "X-API-Key"
    - "X-Requested-With"
    - "Accept"
    - "Origin"
